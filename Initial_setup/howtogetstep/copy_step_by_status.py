# Copyright [2025] [OBARA (Nanjing) Electromechanical Co., Ltd]
#
# Licensed under the Apache License, Version 2.0 (the "License");
# you may not use this file except in compliance with the License.
# You may obtain a copy of the License at
#
#     http://www.apache.org/licenses/LICENSE-2.0
#
# Unless required by applicable law or agreed to in writing, software
# distributed under the License is distributed on an "AS IS" BASIS,
# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
# See the License for the specific language governing permissions and
# limitations under the License.

import os
import shutil
import csv
import time
from collections import defaultdict
from concurrent.futures import ThreadPoolExecutor, as_completed

# ------------------ é…ç½®ï¼šå·²æ›¿æ¢ä¸º Y: ç›˜æ˜ å°„è·¯å¾„ ------------------
SOURCE_DIRS = [
    r"Y:\è®¾è®¡ä¸€è¯¾3Dèµ„æ–™\03-SV GUN STEP",
    r"Y:\å‰åˆ©æ ‡å‡†åŒ–\07å‰åˆ©åº“STEP",
    r"Y:\ä¸Šæµ·3Då›¾åº“æ‹·è´æ–‡ä»¶\03-SV GUN STEP",
    r"Y:\ä¸Šæµ·3Då›¾åº“æ‹·è´æ–‡ä»¶\å‰åˆ©æ ‡å‡†åŒ–\07å‰åˆ©åº“STEP",
    r"Y:\è®¾è®¡ä¸€è¯¾3Dèµ„æ–™\01-SV GUN ASSY\13-PSA\00-STP",
    r"Y:\è®¾è®¡ä¸€è¯¾3Dèµ„æ–™\01-SV GUN ASSY\16-æ’å¤§-X2CV2-TOL\STP",
    r"Y:\è®¾è®¡ä¸€è¯¾3Dèµ„æ–™\01-SV GUN ASSY\17-é“ç„Šé’³\03-STP",
    r"Y:\è®¾è®¡ä¸€è¯¾3Dèµ„æ–™\01-SV GUN ASSY\18-è”šæ¥-X2CV2-TOL\STEP",
    r"Y:\è®¾è®¡ä¸€è¯¾3Dèµ„æ–™\01-SV GUN ASSY\21-ç¦å»ºå¥”é©°\STP",
    r"Y:\è®¾è®¡ä¸€è¯¾3Dèµ„æ–™\01-SV GUN ASSY\22-å°åº¦\STP",
    r"Y:\è®¾è®¡ä¸€è¯¾3Dèµ„æ–™\01-SV GUN ASSY\25-ç†æƒ³-X2CV2-TOL\STP",
    r"Y:\è®¾è®¡ä¸€è¯¾3Dèµ„æ–™\01-SV GUN ASSY\26-æµ·æ–¯å¦æ™®\01-STP",
    r"Y:\è®¾è®¡ä¸€è¯¾3Dèµ„æ–™\01-SV GUN ASSY\30-æ¯”äºšè¿ª\01-STP",
    r"Y:\è®¾è®¡ä¸€è¯¾3Dèµ„æ–™\X2C V2æ ‡å‡†åŒ–æ•°æ®\000-STEP"
]

# æœ¬åœ°è·¯å¾„
current_dir = os.path.dirname(os.path.abspath(__file__))
target_dir = r"T:\Profile\tempstep"  # ä¿®æ”¹ç›®æ ‡ç›®å½•
list_file = os.path.join(current_dir, "comparison_result.csv")  # ä¿®æ”¹æ¸…å•æ–‡ä»¶
log_file = os.path.join(current_dir, "Copy step list.csv")

os.makedirs(target_dir, exist_ok=True)

# ------------------ å·¥å…·å‡½æ•°ï¼šæ–‡ä»¶åæ¸…ç† ------------------
def clean_filename(name):
    """æ¸…ç†æ–‡ä»¶åï¼šå»ç»“å°¾Lï¼Œå»L(å‰éƒ¨åˆ†ï¼Œè½¬å°å†™"""
    if name.endswith("L"):
        name = name[:-1]
    if "L(" in name:
        parts = name.split("L(")
        name = parts[0]
    return name.lower()

# ------------------ æ¸…ç†ç›®æ ‡ç›®å½• ------------------
print("ğŸ§¹ æ¸…ç†ç›®æ ‡ç›®å½•...")
clean_count = 0
for file in os.listdir(target_dir):
    if file.lower().endswith(".step"):
        try:
            os.remove(os.path.join(target_dir, file))
            clean_count += 1
        except Exception as e:
            print(f"âš ï¸ åˆ é™¤æ—§æ–‡ä»¶å¤±è´¥: {file} - {e}")
print(f"âœ… å·²æ¸…ç† {clean_count} ä¸ªæ—§æ–‡ä»¶")

# ------------------ æ„å»ºç´¢å¼•ï¼šæŒ‰å‰4å­—ç¬¦åˆ†ç»„ï¼Œä¿ç•™ä¼˜å…ˆçº§ ------------------
print("â³ æ­£åœ¨æ„å»ºå…¨å±€ç´¢å¼•...")
index = defaultdict(list)  # prefix_key -> [(clean_base, src_filename, src_dir), ...]
start_time = time.time()

for src_dir in SOURCE_DIRS:
    try:
        if not os.path.exists(src_dir):
            print(f"âš ï¸ è·¯å¾„ä¸å­˜åœ¨æˆ–æ— æƒé™: {src_dir}")
            continue
        with os.scandir(src_dir) as entries:
            for entry in entries:
                if entry.is_file() and entry.name.lower().endswith(".step"):
                    base_name = os.path.splitext(entry.name)[0]
                    clean_base = clean_filename(base_name)
                    prefix_key = clean_base[:4] if len(clean_base) >= 4 else clean_base
                    index[prefix_key].append((clean_base, entry.name, src_dir))
    except Exception as e:
        print(f"âš ï¸ ç›®å½•æ‰«æå¤±è´¥: {src_dir} - {e}")

index_time = time.time() - start_time
total_indexed = sum(len(v) for v in index.values())
print(f"âœ… ç´¢å¼•å®Œæˆ: {len(index)} ä¸ªå‰ç¼€ç»„, {total_indexed} ä¸ªæ–‡ä»¶, è€—æ—¶ {index_time:.2f}ç§’")

# ------------------ è¯»å–å¾…å¤„ç†æ–‡ä»¶åˆ—è¡¨ ------------------
try:
    with open(list_file, "r", encoding="utf-8-sig") as f:
        reader = csv.reader(f)
        next(reader)  # è·³è¿‡è¡¨å¤´
        all_lines = []
        for row in reader:
            if row and len(row) >= 5 and row[4] == "å…¨éƒ¨ä¸å­˜åœ¨":  # åªå¤„ç†çŠ¶æ€ä¸º"å…¨éƒ¨ä¸å­˜åœ¨"çš„è¡Œ
                all_lines.append(row[0].strip())
    print(f"ğŸ“‹ ä»comparison_result.csvä¸­ç­›é€‰å‡ºçŠ¶æ€ä¸º'å…¨éƒ¨ä¸å­˜åœ¨'çš„è¡Œï¼Œå…± {len(all_lines)} ä¸ªæ–‡ä»¶")
except Exception as e:
    print(f"ğŸ”¥ CSVè¯»å–å¤±è´¥: {e}")
    exit(1)

total_files = len(all_lines)
print(f"ğŸ“‹ å¾…å¤„ç†æ–‡ä»¶æ•°: {total_files}")

# é¢„å¤„ç†æœç´¢å
search_items = [(orig, clean_filename(orig)) for orig in all_lines]

# ------------------ å¹¶è¡Œå¤„ç†å‡½æ•° ------------------
def process_item(item):
    original_name, search_name = item
    dst_file = os.path.join(target_dir, f"{original_name}.STEP")
    prefix_key = search_name[:4] if len(search_name) >= 4 else search_name

    # åœ¨å¯¹åº”å‰ç¼€ç»„ä¸­æŸ¥æ‰¾
    if prefix_key in index:
        for clean_base, src_filename, src_dir in index[prefix_key]:
            if clean_base.startswith(search_name):  # âœ… å®Œå…¨ä¿æŒåŸåŒ¹é…é€»è¾‘
                for attempt in range(3):
                    try:
                        src_path = os.path.join(src_dir, src_filename)
                        shutil.copy2(src_path, dst_file)
                        return {
                            "status": "success",
                            "original": original_name,
                            "copied": src_filename,
                            "source": src_dir
                        }
                    except Exception as e:
                        if attempt < 2:
                            time.sleep(2 ** attempt)
                        else:
                            return {
                                "status": "error",
                                "original": original_name,
                                "copied": f"å¤åˆ¶å¤±è´¥: {e}",
                                "source": src_dir
                            }
    return {
        "status": "not_found",
        "original": original_name,
        "copied": "æœªæ‰¾åˆ°",
        "source": ""
    }

# ------------------ å¤šçº¿ç¨‹æ‰§è¡Œ ------------------
print("ğŸ“¦ å¼€å§‹å¹¶è¡Œå¤åˆ¶...")
result_log = []
found_count = 0
not_found_count = 0
copy_errors = 0

with ThreadPoolExecutor(max_workers=12) as executor:
    futures = [executor.submit(process_item, item) for item in search_items]
    completed_count = 0
    total = len(futures)
    for future in as_completed(futures):
        result = future.result()
        result_log.append(result)
        if result["status"] == "success":
            found_count += 1
        elif result["status"] == "not_found":
            not_found_count += 1
        elif result["status"] == "error":
            copy_errors += 1
        completed_count += 1
        if completed_count % 10 == 0 or completed_count == total:
            print(f"â³ å¤åˆ¶ä¸­: {completed_count}/{total} æ–‡ä»¶")

# ------------------ å†™å…¥æ—¥å¿— ------------------
print("ğŸ“ å†™å…¥æ—¥å¿—...")
with open(log_file, "w", encoding="utf-8", newline="") as f:
    writer = csv.writer(f)
    writer.writerow(["åŸå§‹æ–‡ä»¶å", "å®é™…å¤åˆ¶æ–‡ä»¶å", "æ¥æºè·¯å¾„"])
    for res in result_log:
        writer.writerow([res["original"], res["copied"], res["source"]])

# ------------------ è¾“å‡ºç»Ÿè®¡ ------------------
total_time = time.time() - start_time
print("\n" + "=" * 60)
print(f"âœ… æ“ä½œå®Œæˆ! ç»“æœå·²ä¿å­˜è‡³: {log_file}")
print(f"ğŸ“ å¤„ç†ç»Ÿè®¡:")
print(f"  æ€»æ–‡ä»¶æ•°: {total_files}")
print(f"  âœ… æˆåŠŸå¤åˆ¶: {found_count} ({found_count/total_files:.1%})")
print(f"  âŒ æœªæ‰¾åˆ°: {not_found_count} ({not_found_count/total_files:.1%})")
print(f"  âš ï¸ å¤åˆ¶é”™è¯¯: {copy_errors}")
print(f"â±ï¸ æ€»è€—æ—¶: {total_time:.1f}ç§’ | å¹³å‡é€Ÿåº¦: {total_files / max(1, total_time):.1f} æ–‡ä»¶/ç§’")
print("=" * 60)

if (not_found_count + copy_errors) / max(1, total_files) > 0.5:
    print("\nâš ï¸ è­¦å‘Š: è¶…è¿‡50%çš„æ–‡ä»¶å¤„ç†å¤±è´¥ï¼è¯·æ£€æŸ¥ Y: ç›˜è¿æ¥çŠ¶æ€ã€‚")